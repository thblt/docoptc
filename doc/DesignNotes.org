This document is a notebook/todo list on the design of docoptc,
including notes on syntax extensions, extra features and code
generation.

The initial objective of DocOptC is to compile the full syntax to
different target languages, probably [[#code-generation][through
intermediate pseudocode]]. The /final/ objective of the project is to
provide a complete framework for command-line parsing and execution,
which would allow to write interface-agnostic applications and delegate
the whole process of analysing arguments, finding the correct entry
point and passing relevant arguments to code generated by docoptc.

* Contents :TOC:
 - [[#syntax-extensions][Syntax extensions]]
   - [[#runtime-customization][Runtime customization]]
   - [[#error-messages-customization][Error messages customization]]
   - [[#subcommands-management][Subcommands management]]
   - [[#parameters-translation][Parameters translation]]
   - [[#validation][Validation]]
   - [[#special-arg-prefix-flag-argumentsxorg-like-argumentswindows-mode][Special arg prefix: flag arguments/Xorg-like arguments/Windows mode]]
   - [[#literal-relationships][Literal relationships]]
 - [[#code-generation][Code generation]]
 - [[#i18n][i18n]]
 - [[#docoptc-as-a-framework][DocOptC as a framework]]
   - [[#entrypoint-configuration][Entrypoint configuration]]
   - [[#validation-and-error-reporting-in-framework-mode][Validation and error reporting in framework mode]]

* Syntax extensions

As a general rule, most syntax extensions could build on DocOpt's
=[default: <value>]= native syntax, replacing =default= with =docoptc=
or something similar.

** Runtime customization

** Error messages customization

Not planned yet.

Only one thing: since DocOpt can't (and shouldn't) perform a full
validation of input parameters, the program must have a way to report
errors in these parameters. It should be able to do this in a way
independant of the interface, that is, without knowledge of the actual
command-line parameters. We should then provide an interface (a
function) which can be called with a) the incorrect value and b) an
error message, and which would automatically locate the erroneous
parameter, and print the message. In C, that could be implemented by
having the program provide a pointer to the erroneous value to the error
function, and docoptc code will use the pointer itself to identify the
erroneous flag. In Python, classes extending native types can be used.
In Haskell,

** Subcommands management

It is common for complex command-line applications to be invoked with
subcommands, and even sometimes nested subcommands. Package managers and
version control systems have been doing this for a long time.

DocOpt intrinsically distinguishes three types of parameters that can be
provided on a command-line:

1. Options, in the form of flags (-a, --all)
2. Arguments (positionals)
3. Commands (literal positionals)

Subcommands can be implemented as literal positionals, but this has a
few limitations:

1. Subcommands having their own parameters, usage patterns and help
   messages must be handled manually.
2. Leads to duplication between code an usage strings: subcommands are
   defined in code, then defined again in docopt.
3. Subcommands may be nested, e.g. =git remote <name> add-url=.
4. Some subcommands may need access to the subcommand tree. =help=" is a
   good example.

A subcommand framework implemented in docopt would be able to:

1. Handle a tree of subcommands, that could either be loaded from a tree
   of text files (usage strings) or, much better, from special markers
   in the code itself (that may be Python's docstrings, or specially
   formatted comments, or whatever structure the language allows)
2. Provide at least a default implementation of the =help= subcommand.
3. Provide at least a default implementation of the =--view-commands=
   option.
4. Allow the user to map functions to subcommands, and deal with
   executing the correct function.
5. Allow the subcommand tree to be edited at runtime, to deal with
   plugins/extensions/etc.
6. Handle common/shared options, like verbosity or simulate mode, that
   could be set at a relatively high level and then forwarded to
   subcommands.

   -  or even set separately (using a logic of "partial" files) and
      called by the subcommands which use them in their docopt file,
      using a syntax extension.

** Parameters translation

*** Parameters translation


The original Docopt syntax requires much less code to construct
arguments, program, but its output may require extra
analysis. Parameters translation could avoid this.  Constructs like
this:

#+BEGIN_EXAMPLE
    Usage:
      program [-v... | -q]
#+END_EXAMPLE

Where =-v= stands for verbose (it can be repeated, it increases
verbosity rather than just enabling it) and =-q= for quiet (disable all
output) should be output to a single variable, that could be called
=logLevel=.

The docopt syntax could be extended to handle this by using a construct
similar to =[default= (value)]=. Something like:

#+BEGIN_EXAMPLE
    Usage:
      program [-v... | -q]

    Options:
      -v, --verbose    Increase verbosity [docoptc: translate:target=logLevel, action=(+1),default=0]
      -q, --quiet      Disable all output [docoptc: translate:target=logLevel, action=(-1)]
#+END_EXAMPLE

The generated hashmap/struct/type whatever will then contain a single
=logLevel= field with a directly usable value, instead of two
"--verbose" and "--quiet" fields requiring manual handling.

*** Value types

Values can also require some translation. A parameter such as
=-d, --depth <depth>= could be exposed as an int to the program instead
of a string (this would add rudimentary automatic validation)

#+begin_EXAMPLE
  Options:
    --count value::int
#+end_EXAMPLE

** Validation
   :PROPERTIES:
   :CUSTOM_ID: validation
   :END:

*** Parameters validation
    :PROPERTIES:
    :CUSTOM_ID: parameters-validation
    :END:

Validation is a complex problem, which should probably be left outside
of docoptc core. Still, validation could be /configured/ from the input
files, using a syntax similar to the one above. docoptc could also
provide some basic validation methods, but leave the huge work of
implementing validation schemas (if necessary) to the user.

A possible basic implementation could look like:

#+BEGIN_EXAMPLE
    Usage:
      program [-i <input_file>] [-o <output_file>]

    Options:
      -i, --input <input_file>    The file to read from [docoptc: validate = {fileExists()}]
      -o, --output <output_file>  The file to write to [docoptc: validate = {isPath() && canWrite && pathExists ? isFile : fail()}]
#+END_EXAMPLE

A list of possible primitive validation functions

| Function name   | Group    | Description                                                                           |
|-----------------+----------+---------------------------------------------------------------------------------------|
| =isPath=        | FS       | =true= if a string is a legal path in the filesystem. Does *not* imply =pathExists=   |
| =pathExists=    | FS       | =true= if the path exists (=false= for broken symlinks)                               |
| =isFile=        | FS       | =true= if regular file. Implies =pathExists=                                          |
| =isDir=         | FS       |                                                                                       |
| =isFile=        | FS       |                                                                                       |
| =isSymlink=     | FS       | =true= if path is a symbolic link. Does *not* imply =pathExists=                      |
| =canWrite=      | FS       |                                                                                       |
| =canRead=       | FS       |                                                                                       |
| =canExecute=    | FS       |                                                                                       |
| =matches=       |  Regex   | =true= if parameter matches the regular expression.                                   |

Compound functions may also be exposed for sake of simplicity. Eg
=inputFile= as =isFile && isReadable= ; =isBrokenLink= as
=isSymlink && !pathExists=, etc.

*** Schema-based validation and other advanced validation method.
    :PROPERTIES:
    :CUSTOM_ID: schema-based-validation-and-other-advanced-validation-method.
    :END:

Docoptc's basic validation interface should be able to perform any
computable test on every discrete value. That is, any test can be
performed, but in isolation. Tests for consistency between two or more
values does not fall in docoptc's scope.

Docoptc /may/ yet expose an interface for such validations.

** Special arg prefix: flag arguments/Xorg-like arguments/Windows mode

That is, don't use =-= as the only command marker.

*** Flag arguments

These can be found in some typical unix apps, when =+= and =-= as prefixes mean /enable/ or /disable/, or =+= is just used in some places because reasons.  The gpp preprocessor uses this:

#+begin_EXAMPLE
(...)
 -n : send LF characters serving as macro terminators to output
 +c : use next 2 args as comment start and comment end sequences
 +s : use next 3 args as string start, end and quote character
#+end_EXAMPLE

As well as =Xorg=:

#+begin_EXAMPLE
+bs                    enable any backing store support
-bs                    disable any backing store support
#+end_EXAMPLE


*** Xorg-like arguments/Windows mode

 - Xorg :: uses =-= as its only parameter mark, in short and long form.
 - Windows =cmd.exe= :: uses =/= the same way.  Powershell seems to go the Xorg way.

Just using =/= instead of, same prefix for short and long form.

** Literal relationships

Many help pages contains annotations like (=implies --other-flag)=, =(requires --other-flag=value)=.  We could parse them.

* Code generation
  :PROPERTIES:
  :CUSTOM_ID: code-generation
  :END:

/Use an intermediate, abstract code representation that can be
translated into actual codes for different languages./

Parsing options is a relatively trivial task, which may be performed in
strikingly similar ways in various languages.

DocOptC's code generation will then be built as a two-step process.
After parsing the help screen, and from an abstract representation of
the command-line options:

1) a language-agnostic, abstract syntax tree will be generated, which
   could-be considered as in-memory pseudocode. There may be more than
   one AST (“pseudocode”) syntax, but there should be as few as
   possible, and they should be as generic as possible. By default,
   there could be two of them: procedural (and optionally object) and
   functional. The actual AST generator is defined by the chosen target
   language: Python and C or C++ will require procedural pseudocode,
   Haskell, Erlang or Scala will pick the functional generator.
2) The generated, in-memory pseudocode will then be translated to
   actual, compilable (or interpretable) code. The pseudocode should be
   generic and verbose enough so that generating actual code be only a
   matter of substituting strings.

As much as possible, translation should be a simple matter of replacing
constructs and correctly placing parameters. Eg, the construict
=PARSE_FUNCTION { functionName :: String, functionBody :: AST }= could
be translated by the C generator as
=docoptc_args * {functionName} (int argc, char * argv[])= and in Python
by =def {functionName} (args = sys.argv):=. Body expansion will
automatically add braces/indent as defined by the language.

Adding a target language would then mean two steps: a) choosing a
pseudo-code generator, and b) writing a series of translations between
AST elements and actual code.

It could be cool to provide a special generator that will simply dump
the AST in a syntax usable by common preprocessors, like cpp or gpp.

The following usage pattern for the imaginary =tig= program:

#+BEGIN_EXAMPLE
    Usage:
      tig [-v|-q] (init <dir>|clone <url>|pull|push|help)

    Options:
      -v, --verbose    Be verbose.
      -q, --quiet      Be quiet.
#+END_EXAMPLE

May then produce the following AST (LISP-like pseudo-syntax, =BLOCK= is
=progn=)

#+BEGIN_EXAMPLE
    (DOCOPT_CONTEXT (
        (TARGET_MAP (T_STRING ; T_BOOL) (BLOCK
            DECLARE_KEY "init" T_BOOL;
            DECLARE_KEY "clone" T_BOOL;
            DECLARE_KEY "push" T_BOOL;
            DECLARE_KEY "pull" T_BOOL;
            DECLARE_KEY "help" T_BOOL;
            DECLARE_KEY "<dir>" T_STRING;
            DECLARE_KEY "<url>" T_STRING;
            DECLARE_KEY "--verbose" T_BOOL;
            DECLARE_KEY "--quiet" T_BOOL;
            )
        (PARSE_FUNCTION (BLOCK
            (IF (NOT_EQUALS (ARGV 0) "tig") (FAIL ())
            LOOP (ARGV[1:]
#+END_EXAMPLE

A C generator may translate DECLARE\_TARGET\_MAP to =typedef struct=,
translate names from =<dir>= to =DIR= and =--verbose= to =__verbose=,
where a Python translator may init an =object= and a Haskell one either
create a =Map= or a new type.

* i18n

Proper internationalization may be hard to achieve using the default
docopt implementation. Docoptc may provide a way to either:

-  Extract strings from docopt files to =.po= files (or to a simplified
   format)
-  Load localizations of a docopt file.

or:

- If translations are complete docopt inputs, provide a way to check
  that they're technically identical to the master file (some =docoptc
  i18n check= command)
- Avoid repetitions:
  - Syntax extensions markers don't have to be present in translations.
  - More generally, translations should be processed as translations,
    not as full docopt input.  They replace strings, but don't have to
    repeat the original file.  Their header should contain only two
    lines =translates:= and =locale:=.  This implies that the compiler
    should provide a command to generate a minimal translation source
    file: =docoptc i18n strip=.

*Note*: it is assumed here that internationalization only apply to the
documentation, not to the command themselves. Using parameters
translation, positional placeholders may be translated as well, but it
would probably be a /Very Bad Idea/ to translate long command names, and
thus won't be supported.

* DocOptC as a framework
  :PROPERTIES:
  :CUSTOM_ID: docoptc-as-a-framework
  :END:

Having DocOptc behave as a framework means that the user writes an
interface-agnostic code (basically a library) and command-line usage
screens in extended DocOptC syntax, and DocOptC will generate a =main()=
function which will:

-  process parameters
-  validate individual arguments
-  call extra validators if needed
-  call the correct function with arguments in order.

** Entrypoint configuration
   :PROPERTIES:
   :CUSTOM_ID: entrypoint-configuration
   :END:

Complex applications have more than one entry point, or controller
function. Even the simplest of apps usually have a true main function
(which does the actual work) and small utility functions like
=print_help= or =print_version=. DocOptC as a framework could deal with
this by adding a configuration key for options and subcommands. This
syntax could be enough for a start:

#+BEGIN_EXAMPLE
    -h, --help       Print this help [docoptc | entryPoint: docoptc_print_usage()]
#+END_EXAMPLE

*** Entrypoints with parameters
    :PROPERTIES:
    :CUSTOM_ID: entrypoints-with-parameters
    :END:

Using parameters translation and automatic type conversion, DocOptC
could allow calling an entrypoint with parameters. The syntax could look
like :

| Syntax                                          | Meaning                                     |
|-------------------------------------------------+---------------------------------------------|
| =entryPoint: myFunc()=                          | No parameters                               |
| =entryPoint: myFunc(*)=                         | All command-line parameters in a "struct"   |
| =entryPoint: myFunc(namedArg1, namedArg2...)=   | These named parameters, in that order.      |

The entrypoints is not technically the combination of a function and its
parameter, but a symbol and a list of parameters. Java code generation,
for instance, may translate =MyObject.myFunc(namedArg1,namedArg3= as:

#+BEGIN_EXAMPLE
    MyObject mo = MyObject();
    return mo.myFunc(namedArg1, namedArg3);
#+END_EXAMPLE

or even more complex construct such as
=MyObject(namedArg1).myFunc(namedArg3)= as

#+BEGIN_EXAMPLE
    MyObject mo = MyObject(namedArg1);
    return mo.myFunc(namedArg3);
#+END_EXAMPLE

The exact meaning of entrypoint parameters is specified at the code
generator configuration level.

** Validation and error reporting in framework mode
   :PROPERTIES:
   :CUSTOM_ID: validation-and-error-reporting-in-framework-mode
   :END:

DocOptC provides formal validation for isolated parameters. Working as a
framework, this is more than enough to pass valid data to functions. In
the rare cases where schema-based validation be required, it could be
accomplished in two ways:

1. Let the entrypoint function perform the validation, which seems a
   logical approach: as the entrypoint is a "library" function, it may
   receive invalid values from any consumer, and thus should validate
   them anyway. This approach is good, but have a limitation: it won't
   allow (if code is expected to be unaware of the interface used to
   access it) to report which value, or group of values, was invalid or
   inconsistent, in the terms used to provide them in the CLI. For
   instance, if this program:

   #+BEGIN_EXAMPLE
       Usage:
       myprog <file> <start> <end> [docoptc: entryPoint: mainFunction(file, start, end)]

       Positionals:
       <file>     The file to inspect. [docoptc: validate: inputFile()]
       <start>    The start offset. [docoptc: validate: integer(0, INT_MAX)]
       <end>      The end offset. [docoptc: validate: integer(0, INT_MAX)]
   #+END_EXAMPLE

   This program obviously does something in a part of a file, ranging
   from =start= to =end=. DocOptC properly validates that =start= and
   =end= are null or positive integers, but doesn't enforce other
   obvious requirements: that =end >= start=, and that =end <= size= of
   file.

   =mainFunction= may report these errors, but it won't be able to tell
   if the parameters were positional, named options are entered in any
   other way. That's good enough for such a simple program, but won't be
   sufficient for more complex apps where reporting exactly what the
   inconsistencies in input were may be really helpful.

   In some languages (e.g., Python), DocOptC could pass tagged values
   that could be use exactly as native types, but which would also carry
   informations about where they were set. Thus, providing a
   =abort_with_parameters_error= function may allow the @TODO

2. The user may provide a bridge function. The entrypoint setting will
   then look like =[docoptc: entryPoint: mainFunctionBridge(*)]=
